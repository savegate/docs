---
title: "Supported Models"
description: "Complete list of AI models available through SaveGate"
---

## Overview

SaveGate provides access to 50+ state-of-the-art AI models from leading providers. All models are accessible through a unified API using the same authentication and request format.

## OpenAI Models

### GPT-5.1 Family (Latest)

<CardGroup cols={2}>
  <Card title="GPT-5.1" icon="brain">
    **Model ID:** `gpt-5.1`

    - Most advanced GPT model
    - Superior reasoning capabilities
    - Enhanced multimodal understanding
    - Best for complex tasks
  </Card>

  <Card title="GPT-5.1 Mini" icon="bolt">
    **Model ID:** `gpt-5.1-mini`

    - Faster and more affordable
    - Excellent performance/cost ratio
    - Good for most tasks
  </Card>

  <Card title="GPT-5.1 Reasoning" icon="graduation-cap">
    **Model ID:** `gpt-5.1-reasoning`

    - Specialized for complex reasoning
    - Extended thinking time
    - Best for analysis and problem-solving
  </Card>
</CardGroup>

### GPT-4.2 Family

<CardGroup cols={2}>
  <Card title="GPT-4.2" icon="star">
    **Model ID:** `gpt-4.2`

    - Advanced capabilities
    - Improved performance
    - Great balance of speed and quality
  </Card>

  <Card title="GPT-4.2 Mini" icon="zap">
    **Model ID:** `gpt-4.2-mini`

    - Fast and efficient
    - Cost-effective
    - Good for high-volume tasks
  </Card>

  <Card title="GPT-4.2 Reasoning" icon="brain-circuit">
    **Model ID:** `gpt-4.2-reasoning`

    - Enhanced reasoning capabilities
    - Complex problem solving
    - Mathematical and logical tasks
  </Card>
</CardGroup>

### GPT-4.1 Family

<CardGroup cols={2}>
  <Card title="GPT-4.1" icon="sparkles">
    **Model ID:** `gpt-4.1`

    - Reliable performance
    - Balanced capabilities
    - Production-ready
  </Card>

  <Card title="GPT-4.1 Mini" icon="bolt">
    **Model ID:** `gpt-4.1-mini`

    - Lightweight and fast
    - Good value
    - High throughput
  </Card>

  <Card title="GPT-4.1 Nano" icon="microchip">
    **Model ID:** `gpt-4.1-nano`

    - Ultra-lightweight
    - Fastest response times
    - Most cost-effective
  </Card>
</CardGroup>

### GPT-4o Family

<CardGroup cols={2}>
  <Card title="GPT-4o" icon="eye">
    **Model ID:** `gpt-4o`

    - Multimodal (text + vision)
    - Fast and efficient
    - Context: 128K tokens
  </Card>

  <Card title="GPT-4o Mini" icon="feather">
    **Model ID:** `gpt-4o-mini`

    - Lightweight multimodal
    - Cost-effective
    - Good for simple tasks
  </Card>

  <Card title="GPT-4o Realtime" icon="broadcast-tower">
    **Model ID:** `gpt-4o-realtime`

    - Real-time audio/video
    - Low latency
    - Interactive applications
  </Card>

  <Card title="GPT-4o Transcribe" icon="microphone">
    **Model ID:** `gpt-4o-transcribe`

    - Audio transcription
    - High accuracy
    - Multiple languages
  </Card>

  <Card title="GPT-4o Mini Transcribe" icon="file-audio">
    **Model ID:** `gpt-4o-mini-transcribe`

    - Lightweight transcription
    - Fast processing
    - Cost-effective
  </Card>
</CardGroup>

### O-Series (Reasoning Models)

<CardGroup cols={2}>
  <Card title="O3" icon="graduation-cap">
    **Model ID:** `o3`

    - Advanced reasoning
    - Complex problem solving
    - Extended thinking time
    - Best for difficult tasks
  </Card>

  <Card title="O3 Mini" icon="brain">
    **Model ID:** `o3-mini`

    - Faster reasoning model
    - Good balance
    - Cost-effective reasoning
  </Card>
</CardGroup>

### Classic GPT-4 Family

<CardGroup cols={2}>
  <Card title="GPT-4" icon="crown">
    **Model ID:** `gpt-4`

    - Original GPT-4
    - Proven reliability
    - Context: 8K tokens
  </Card>

  <Card title="GPT-4 Turbo" icon="rocket">
    **Model ID:** `gpt-4-turbo`

    - Faster than GPT-4
    - Context: 128K tokens
    - JSON mode support
  </Card>
</CardGroup>

### GPT-3.5 Family

| Model ID | Context | Best For |
|----------|---------|----------|
| `gpt-3.5-turbo` | 16K | General tasks, cost-effective |

### Whisper Models

<Card title="Whisper Large v3" icon="microphone-lines">
  **Model ID:** `whisper-large-v3`

  - State-of-the-art speech recognition
  - 99 languages supported
  - High accuracy transcription
  - Timestamp support
</Card>

## Anthropic Claude Models

### Claude 4.5 Family (Latest)

<CardGroup cols={2}>
  <Card title="Claude Opus 4.5" icon="crown">
    **Model ID:** `claude-opus-4.5`

    - Most capable Claude model
    - Superior reasoning and analysis
    - Context: 200K tokens
    - Best for complex tasks
  </Card>

  <Card title="Claude Sonnet 4.5" icon="sparkles">
    **Model ID:** `claude-sonnet-4.5`

    - Latest Sonnet version
    - Excellent balance
    - Fast and capable
    - Great for coding
  </Card>
</CardGroup>

### Claude 4.1 Family

<Card title="Claude Opus 4.1" icon="gem">
  **Model ID:** `claude-opus-4.1`

  - High capability model
  - Advanced reasoning
  - Context: 200K tokens
  - Complex problem solving
</Card>

### Claude 4 Family

<CardGroup cols={2}>
  <Card title="Claude Opus 4" icon="star">
    **Model ID:** `claude-opus-4`

    - Powerful capabilities
    - Long context
    - Reliable performance
  </Card>

  <Card title="Claude Sonnet 4" icon="bolt">
    **Model ID:** `claude-sonnet-4`

    - Balanced model
    - Good speed
    - Versatile
  </Card>
</CardGroup>

### Claude 3.7 Family

<Card title="Claude 3.7 Sonnet" icon="sparkles">
  **Model ID:** `claude-3.7-sonnet`

  - Enhanced Sonnet
  - Improved capabilities
  - Context: 200K tokens
  - Great for coding and analysis
</Card>

### Claude 3.5 Family

<CardGroup cols={2}>
  <Card title="Claude 3.5 Sonnet" icon="code">
    **Model ID:** `claude-3.5-sonnet`

    - Best balance of speed/capability
    - Context: 200K tokens
    - Excellent for coding
  </Card>

  <Card title="Claude 3.5 Haiku" icon="wind">
    **Model ID:** `claude-3.5-haiku`

    - Fastest Claude 3.5
    - Cost-effective
    - Good for simple tasks
  </Card>
</CardGroup>

### Claude 3 Family

<CardGroup cols={2}>
  <Card title="Claude 3 Opus" icon="star">
    **Model ID:** `claude-3-opus`

    - Most capable Claude 3
    - Context: 200K tokens
    - Complex tasks
  </Card>

  <Card title="Claude 3 Sonnet" icon="balance-scale">
    **Model ID:** `claude-3-sonnet`

    - Balanced performance
    - Good for most tasks
    - Context: 200K tokens
  </Card>

  <Card title="Claude 3 Haiku" icon="feather">
    **Model ID:** `claude-3-haiku`

    - Fastest Claude 3
    - Most cost-effective
    - Context: 200K tokens
  </Card>
</CardGroup>

### Claude 2 Family

| Model ID | Context | Best For |
|----------|---------|----------|
| `claude-2.1` | 200K | Long documents, analysis |
| `claude-2` | 100K | General tasks |
| `claude-instant-1.2` | 100K | Fast responses, high volume |

## Model Selection Guide

### By Use Case

<Tabs>
  <Tab title="Coding">
    **Best Models:**
    1. `claude-sonnet-4.5` - Best overall for coding
    2. `gpt-5.1` - Advanced code generation
    3. `claude-3.7-sonnet` - Excellent code understanding
    4. `gpt-4.2` - Strong alternative

    **Why:** Advanced reasoning, code understanding, and generation
  </Tab>

  <Tab title="Writing">
    **Best Models:**
    1. `gpt-5.1` - Creative writing
    2. `claude-opus-4.5` - Long-form content
    3. `claude-sonnet-4.5` - Balanced quality
    4. `gpt-4.2` - General writing

    **Why:** Natural language generation, creativity, coherence
  </Tab>

  <Tab title="Analysis">
    **Best Models:**
    1. `gpt-5.1-reasoning` - Complex reasoning
    2. `o3` - Advanced problem solving
    3. `claude-opus-4.5` - Document analysis
    4. `gpt-4.2-reasoning` - Data analysis

    **Why:** Deep reasoning, understanding, insights
  </Tab>

  <Tab title="Chat">
    **Best Models:**
    1. `gpt-4o` - Multimodal chat
    2. `claude-sonnet-4.5` - Conversational
    3. `gpt-5.1-mini` - Fast and capable
    4. `gpt-3.5-turbo` - Cost-effective

    **Why:** Fast responses, natural conversation, affordable
  </Tab>

  <Tab title="Transcription">
    **Best Models:**
    1. `whisper-large-v3` - Best accuracy
    2. `gpt-4o-transcribe` - High quality
    3. `gpt-4o-mini-transcribe` - Cost-effective

    **Why:** Speech recognition, multilingual support
  </Tab>
</Tabs>

### By Budget

<AccordionGroup>
  <Accordion title="Premium (Best Performance)" icon="crown">
    - `gpt-5.1` - Most advanced GPT
    - `gpt-5.1-reasoning` - Advanced reasoning
    - `claude-opus-4.5` - Most capable Claude
    - `o3` - Complex problem solving

    **Use when:** Quality is critical, complex tasks
  </Accordion>

  <Accordion title="Balanced (Good Value)" icon="scale-balanced">
    - `gpt-5.1-mini` - Great performance/cost
    - `claude-sonnet-4.5` - Best overall value
    - `gpt-4.2` - Fast and capable
    - `claude-3.7-sonnet` - Excellent coding

    **Use when:** Need quality at reasonable cost
  </Accordion>

  <Accordion title="Budget (Cost-Effective)" icon="piggy-bank">
    - `gpt-4.1-nano` - Ultra-lightweight
    - `gpt-3.5-turbo` - Fast and cheap
    - `claude-3.5-haiku` - Fastest Claude
    - `gpt-4.2-mini` - Good value

    **Use when:** Simple tasks, high volume
  </Accordion>
</AccordionGroup>

## Model Capabilities

### Function Calling

Models that support function/tool calling:

- ✅ All GPT-5.1, GPT-4.2, GPT-4.1 models
- ✅ GPT-4o, GPT-4o Mini
- ✅ GPT-4, GPT-4 Turbo
- ✅ GPT-3.5 Turbo
- ✅ All Claude 4.5, 4.1, 4, 3.7, 3.5, 3 models
- ✅ Claude 2.1

### Vision (Multimodal)

Models that support image understanding:

- ✅ GPT-5.1 family
- ✅ GPT-4.2, GPT-4.1
- ✅ GPT-4o, GPT-4o Mini, GPT-4o Realtime
- ✅ All Claude 4.5, 4.1, 4 models
- ✅ Claude 3.7, 3.5, 3 family

### Audio & Transcription

Models with audio capabilities:

- ✅ `whisper-large-v3` - Speech recognition
- ✅ `gpt-4o-transcribe` - Audio transcription
- ✅ `gpt-4o-mini-transcribe` - Fast transcription
- ✅ `gpt-4o-realtime` - Real-time audio/video

### Reasoning

Models specialized for complex reasoning:

- ✅ `gpt-5.1-reasoning` - Advanced reasoning
- ✅ `gpt-4.2-reasoning` - Enhanced reasoning
- ✅ `o3` - Complex problem solving
- ✅ `o3-mini` - Efficient reasoning
- ✅ Claude Opus models - Strong reasoning

## Using Models

Simply specify the model ID in your API request:

<CodeGroup>
```python Python
response = client.chat.completions.create(
    model="gpt-5.1",  # Specify model here
    messages=[{"role": "user", "content": "Hello!"}]
)
```

```javascript Node.js
const response = await client.chat.completions.create({
  model: 'claude-sonnet-4.5',  // Specify model here
  messages: [{ role: 'user', content: 'Hello!' }]
});
```
</CodeGroup>

## Model Updates

SaveGate automatically updates model versions to the latest stable releases. For version pinning, use specific model IDs when available.

<Note>
Check the [pricing page](/concepts/pricing) for detailed cost information for each model.
</Note>
