---
title: "Quickstart"
description: "Get started with SaveGate in under 5 minutes"
---

## Get Your API Key

First, create a free SaveGate account and get your API key.

<Steps>
  <Step title="Sign Up">
    Go to [savegate.ai/signin](https://savegate.ai/signin) and create an account.
  </Step>
  <Step title="Get API Key">
    Navigate to your dashboard and copy your API key from the API Keys section.
  </Step>
</Steps>

<Warning>
Keep your API key secure and never share it publicly. Treat it like a password.
</Warning>

## Make Your First Request

Choose your preferred method to make API calls:

<Tabs>
  <Tab title="Python (OpenAI SDK)">
    ```python
    from openai import OpenAI

    client = OpenAI(
        api_key="your-savegate-api-key",
        base_url="https://api.savegate.ai/v1"
    )

    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "user", "content": "Hello! How are you?"}
        ]
    )

    print(response.choices[0].message.content)
    ```
  </Tab>

  <Tab title="Python (LiteLLM)">
    ```python
    import litellm

    # Set the API base and key
    litellm.api_base = "https://api.savegate.ai/v1"
    litellm.api_key = "your-savegate-api-key"

    response = litellm.completion(
        model="gpt-4",
        messages=[
            {"role": "user", "content": "Hello! How are you?"}
        ]
    )

    print(response.choices[0].message.content)
    ```
  </Tab>

  <Tab title="Node.js">
    ```javascript
    import OpenAI from 'openai';

    const client = new OpenAI({
      apiKey: 'your-savegate-api-key',
      baseURL: 'https://api.savegate.ai/v1'
    });

    async function main() {
      const response = await client.chat.completions.create({
        model: 'gpt-4',
        messages: [
          { role: 'user', content: 'Hello! How are you?' }
        ]
      });

      console.log(response.choices[0].message.content);
    }

    main();
    ```
  </Tab>

  <Tab title="cURL">
    ```bash
    curl https://api.savegate.ai/v1/chat/completions \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer your-savegate-api-key" \
      -d '{
        "model": "gpt-4",
        "messages": [
          {"role": "user", "content": "Hello! How are you?"}
        ]
      }'
    ```
  </Tab>
</Tabs>

## Installation

Install the SDK for your preferred language:

<CodeGroup>
```bash Python (OpenAI)
pip install openai
```

```bash Python (LiteLLM)
pip install litellm
```

```bash Node.js
npm install openai
```

```bash Python (Anthropic)
pip install anthropic
```
</CodeGroup>

## Try Different Models

SaveGate supports 50+ models. Here's how to use models from different providers:

<Tabs>
  <Tab title="OpenAI Models">
    ```python
    # GPT-4
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": "Hello!"}]
    )

    # GPT-4 Turbo
    response = client.chat.completions.create(
        model="gpt-4-turbo",
        messages=[{"role": "user", "content": "Hello!"}]
    )

    # O1
    response = client.chat.completions.create(
        model="o1-preview",
        messages=[{"role": "user", "content": "Solve this problem..."}]
    )
    ```
  </Tab>

  <Tab title="Anthropic Models">
    ```python
    # Claude 3.5 Sonnet
    response = client.chat.completions.create(
        model="claude-3-5-sonnet-20241022",
        messages=[{"role": "user", "content": "Hello!"}]
    )

    # Claude 3 Opus
    response = client.chat.completions.create(
        model="claude-3-opus-20240229",
        messages=[{"role": "user", "content": "Hello!"}]
    )
    ```
  </Tab>

  <Tab title="Google Models">
    ```python
    # Gemini Pro
    response = client.chat.completions.create(
        model="gemini-pro",
        messages=[{"role": "user", "content": "Hello!"}]
    )

    # Gemini 1.5 Pro
    response = client.chat.completions.create(
        model="gemini-1.5-pro",
        messages=[{"role": "user", "content": "Hello!"}]
    )
    ```
  </Tab>

  <Tab title="Meta Models">
    ```python
    # Llama 3 70B
    response = client.chat.completions.create(
        model="meta-llama/llama-3-70b-instruct",
        messages=[{"role": "user", "content": "Hello!"}]
    )
    ```
  </Tab>
</Tabs>

## Enable Streaming

Get real-time responses with streaming:

<CodeGroup>
```python Python
response = client.chat.completions.create(
    model="gpt-4",
    messages=[{"role": "user", "content": "Tell me a story"}],
    stream=True
)

for chunk in response:
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="")
```

```javascript Node.js
const stream = await client.chat.completions.create({
  model: 'gpt-4',
  messages: [{ role: 'user', content: 'Tell me a story' }],
  stream: true
});

for await (const chunk of stream) {
  if (chunk.choices[0]?.delta?.content) {
    process.stdout.write(chunk.choices[0].delta.content);
  }
}
```
</CodeGroup>

## Monitor Your Usage

Track your API usage and costs in real-time:

1. Go to your [SaveGate Dashboard](https://savegate.ai/signin)
2. View usage statistics, cost breakdowns, and performance metrics
3. Set up billing alerts to monitor spending

## Next Steps

<CardGroup cols={2}>
  <Card
    title="Authentication"
    icon="key"
    href="/authentication"
  >
    Learn about API keys and authentication best practices.
  </Card>
  <Card
    title="View All Models"
    icon="list"
    href="/concepts/models"
  >
    Explore the complete list of 50+ supported models.
  </Card>
  <Card
    title="SDK Integration"
    icon="code"
    href="/sdk/litellm"
  >
    Deep dive into LiteLLM and other SDK integrations.
  </Card>
  <Card
    title="API Reference"
    icon="terminal"
    href="/api-reference/chat-completions"
  >
    Explore the complete API documentation.
  </Card>
</CardGroup>
